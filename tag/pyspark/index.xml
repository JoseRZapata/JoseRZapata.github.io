<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pyspark | Jose Ricardo Zapata</title>
    <link>https://joserzapata.github.io/tag/pyspark/</link>
      <atom:link href="https://joserzapata.github.io/tag/pyspark/index.xml" rel="self" type="application/rss+xml" />
    <description>Pyspark</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2020</copyright><lastBuildDate>Mon, 09 Mar 2020 23:00:43 -0500</lastBuildDate>
    <image>
      <url>https://joserzapata.github.io/img/JoseRZapata.jpg</url>
      <title>Pyspark</title>
      <link>https://joserzapata.github.io/tag/pyspark/</link>
    </image>
    
    <item>
      <title>Pyspark con Google Colab</title>
      <link>https://joserzapata.github.io/post/pyspark-google-colab/</link>
      <pubDate>Mon, 09 Mar 2020 23:00:43 -0500</pubDate>
      <guid>https://joserzapata.github.io/post/pyspark-google-colab/</guid>
      <description>&lt;h1 id=&#34;pyspark-en-google-colab-automatico&#34;&gt;PySpark en Google Colab Automatico&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;Instalacion Marzo/2020&lt;/li&gt;
&lt;li&gt;Intalacion Automatica
&lt;ol&gt;
&lt;li&gt;Instalacion Java&lt;/li&gt;
&lt;li&gt;Instalacion de Spark&lt;/li&gt;
&lt;li&gt;Ejemplo de Uso de pyspark&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/JoseRZapata/JoseRZapata.github.io/blob/master/Jupyter_Notebook/Pyspark_Colab_es.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;instalacion-rapida-marzo-2020&#34;&gt;Instalacion Rapida Marzo/ 2020&lt;/h1&gt;
&lt;p&gt;De forma General para usar pyspark en Colab Marzo/2020 seria con los siguientes comandos en una celda en Colab:&lt;/p&gt;
&lt;p&gt;Instalar Java&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;!apt-get install openjdk-8-jdk-headless -qq &amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os # libreria de manejo del sistema operativo
os.system(&amp;quot;wget -q https://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz&amp;quot;)
os.system(&amp;quot;tar xf /spark-2.4.5-bin-hadoop2.7.tgz&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;instalar pyspark&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;!pip install -q pyspark
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Variables de Entorno
os.environ[&amp;quot;JAVA_HOME&amp;quot;] = &amp;quot;/usr/lib/jvm/java-8-openjdk-amd64&amp;quot;
os.environ[&amp;quot;SPARK_HOME&amp;quot;] = f&amp;quot;/content/{ver_spark}-bin-hadoop2.7&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Cargar Pyspark
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName(&amp;quot;Test_spark&amp;quot;).master(&amp;quot;local[*]&amp;quot;).getOrCreate()
spark
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Pero cuando salga una nueva version de spark sera necesario actualizar los
links de descarga, ya que siempre borran las versiones 2.x.x cuando sale una nueva.&lt;/p&gt;
&lt;p&gt;Lo mejor es configurar automaticamente para que descargue la version que sea
mayor que 2.3.4 que es la anterior y menor que spark 3.0.0 que aun se encuentra en desarrollo&lt;/p&gt;
&lt;p&gt;Para esto el siguiente codigo detecta la version actual de spark, la descarga, la descomprime y luego realiza la instalacion de spark en google colab.&lt;/p&gt;
&lt;h1 id=&#34;instalacion-automatica&#34;&gt;Instalacion Automatica&lt;/h1&gt;
&lt;h2 id=&#34;instalacion-de-java&#34;&gt;Instalacion de Java&lt;/h2&gt;
&lt;p&gt;Google Colaboratory funciona en un ambiente linux, por lo tanto se pueden usar comandos shell de linux antecedidos del caracter &amp;lsquo;!&amp;rsquo;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;!apt-get install openjdk-8-jdk-headless -qq &amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;instalacion-de-spark&#34;&gt;Instalacion de Spark&lt;/h2&gt;
&lt;p&gt;Obtener automaticamente la ultima version de spark de&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bs4 import BeautifulSoup
import requests
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#Obtener las versiones de spark la pagina web
url = &#39;https://downloads.apache.org/spark/&#39; 
r = requests.get(url)
html_doc = r.text
soup = BeautifulSoup(html_doc)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# leer la pagina web y obtener las versiones de spark disponibles
link_files = []
for link in soup.find_all(&#39;a&#39;):
  link_files.append(link.get(&#39;href&#39;))
spark_link = [x for x in link_files if &#39;spark&#39; in x]  
print(spark_link)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;[&amp;lsquo;spark-2.3.4/&amp;rsquo;, &amp;lsquo;spark-2.4.5/&amp;rsquo;, &amp;lsquo;spark-3.0.0-preview2/&#39;]&lt;/p&gt;
&lt;p&gt;La version a usar seran las superiores a spark-2.3.4  y menores a spark-3.0.0&lt;/p&gt;
&lt;p&gt;obtener la version y eliminar el caracter &amp;lsquo;/&amp;rsquo; del final&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ver_spark = spark_link[1][:-1] # obtener la version y eliminar el caracter &#39;/&#39; del final
print(ver_spark)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;spark-2.4.5
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os # libreria de manejo del sistema operativo
#instalar automaticamente la version deseadda de spark
link = &amp;quot;https://www-us.apache.org/dist/spark/&amp;quot;
os.system(f&amp;quot;wget -q {link}{ver_spark}/{ver_spark}-bin-hadoop2.7.tgz&amp;quot;)
os.system(f&amp;quot;tar xf {ver_spark}-bin-hadoop2.7.tgz&amp;quot;)

# instalar pyspark
!pip install -q pyspark
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;|████████████████████████████████| 217.8MB 63kB/s 
|████████████████████████████████| 204kB 53.8MB/s 
Building wheel for pyspark (setup.py) ... done
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;definir-variables-de-entorno&#34;&gt;Definir variables de entorno&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;os.environ[&amp;quot;JAVA_HOME&amp;quot;] = &amp;quot;/usr/lib/jvm/java-8-openjdk-amd64&amp;quot;
os.environ[&amp;quot;SPARK_HOME&amp;quot;] = f&amp;quot;/content/{ver_spark}-bin-hadoop2.7&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;cargar-pyspark-en-el-sistema&#34;&gt;Cargar pyspark en el sistema&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;from pyspark.sql import SparkSession
spark = SparkSession.builder.appName(&amp;quot;Test_spark&amp;quot;).master(&amp;quot;local[*]&amp;quot;).getOrCreate()
spark
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;p&gt;&lt;b&gt;SparkSession - in-memory&lt;/b&gt;&lt;/p&gt;
&lt;div&gt;
  &lt;p&gt;&lt;b&gt;SparkContext&lt;/b&gt;&lt;/p&gt;
  &lt;p&gt;&lt;a href=&#34;http://cf857c0401dc:4040&#34;&gt;Spark UI&lt;/a&gt;&lt;/p&gt;
  &lt;dl&gt;
      &lt;dt&gt;Version&lt;/dt&gt;
        &lt;dd&gt;&lt;code&gt;v2.4.5&lt;/code&gt;&lt;/dd&gt;
      &lt;dt&gt;Master&lt;/dt&gt;
        &lt;dd&gt;&lt;code&gt;local[*]&lt;/code&gt;&lt;/dd&gt;
      &lt;dt&gt;AppName&lt;/dt&gt;
        &lt;dd&gt;&lt;code&gt;pyspark-shell&lt;/code&gt;&lt;/dd&gt;
  &lt;/dl&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id=&#34;ejemplo-de-uso-de-pyspark&#34;&gt;Ejemplo de Uso de pyspark&lt;/h1&gt;
&lt;p&gt;Leer archivo de prueba&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;archivo = &#39;./sample_data/california_housing_train.csv&#39;
df_spark = spark.read.csv(archivo, inferSchema=True, header=True)

# imprimir tipo de archivo
print(type(df_spark))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;class &#39;pyspark.sql.dataframe.DataFrame&#39;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;¿Numero de registros en el dataframe?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;df_spark.count()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;17000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Estructura del dataframe&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;df_spark.printSchema()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;root
 |-- longitude: double (nullable = true)
 |-- latitude: double (nullable = true)
 |-- housing_median_age: double (nullable = true)
 |-- total_rooms: double (nullable = true)
 |-- total_bedrooms: double (nullable = true)
 |-- population: double (nullable = true)
 |-- households: double (nullable = true)
 |-- median_income: double (nullable = true)
 |-- median_house_value: double (nullable = true)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;¿Nombre de las Columnas de dataframe?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;df_spark.columns
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[&#39;longitude&#39;,
 &#39;latitude&#39;,
 &#39;housing_median_age&#39;,
 &#39;total_rooms&#39;,
 &#39;total_bedrooms&#39;,
 &#39;population&#39;,
 &#39;households&#39;,
 &#39;median_income&#39;,
 &#39;median_house_value&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ver los primeros 20 registros del dataframe&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;df_spark.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+
|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|
+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+
|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|
|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|
|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|
|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|
|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|
|  -114.58|   33.63|              29.0|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|
|  -114.58|   33.61|              25.0|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|
|  -114.59|   34.83|              41.0|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|
|  -114.59|   33.61|              34.0|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|
|   -114.6|   34.83|              46.0|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|
|   -114.6|   33.62|              16.0|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|
|   -114.6|    33.6|              21.0|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|
|  -114.61|   34.84|              48.0|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|
|  -114.61|   34.83|              31.0|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0|
|  -114.63|   32.76|              15.0|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|
|  -114.65|   34.89|              17.0|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0|
|  -114.65|    33.6|              28.0|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|
|  -114.65|   32.79|              21.0|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0|
|  -114.66|   32.74|              17.0|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|
|  -114.67|   33.92|              17.0|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|
+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+
only showing top 20 rows
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;descricipcion-estadistica-del-dataframe&#34;&gt;Descricipcion Estadistica del dataframe&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df_spark.describe().toPandas().transpose()
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;th&gt;4&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;summary&lt;/td&gt;
&lt;td&gt;count&lt;/td&gt;
&lt;td&gt;mean&lt;/td&gt;
&lt;td&gt;stddev&lt;/td&gt;
&lt;td&gt;min&lt;/td&gt;
&lt;td&gt;max&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;longitude&lt;/td&gt;
&lt;td&gt;17000&lt;/td&gt;
&lt;td&gt;-119.56210823529375&lt;/td&gt;
&lt;td&gt;2.0051664084260357&lt;/td&gt;
&lt;td&gt;-124.35&lt;/td&gt;
&lt;td&gt;-114.31&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;latitude&lt;/td&gt;
&lt;td&gt;17000&lt;/td&gt;
&lt;td&gt;35.6252247058827&lt;/td&gt;
&lt;td&gt;2.1373397946570867&lt;/td&gt;
&lt;td&gt;32.54&lt;/td&gt;
&lt;td&gt;41.95&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;housing_median_age&lt;/td&gt;
&lt;td&gt;17000&lt;/td&gt;
&lt;td&gt;28.58935294117647&lt;/td&gt;
&lt;td&gt;12.586936981660406&lt;/td&gt;
&lt;td&gt;1.0&lt;/td&gt;
&lt;td&gt;52.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;total_rooms&lt;/td&gt;
&lt;td&gt;17000&lt;/td&gt;
&lt;td&gt;2643.664411764706&lt;/td&gt;
&lt;td&gt;2179.947071452777&lt;/td&gt;
&lt;td&gt;2.0&lt;/td&gt;
&lt;td&gt;37937.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;total_bedrooms&lt;/td&gt;
&lt;td&gt;17000&lt;/td&gt;
&lt;td&gt;539.4108235294118&lt;/td&gt;
&lt;td&gt;421.4994515798648&lt;/td&gt;
&lt;td&gt;1.0&lt;/td&gt;
&lt;td&gt;6445.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;population&lt;/td&gt;
&lt;td&gt;17000&lt;/td&gt;
&lt;td&gt;1429.5739411764705&lt;/td&gt;
&lt;td&gt;1147.852959159527&lt;/td&gt;
&lt;td&gt;3.0&lt;/td&gt;
&lt;td&gt;35682.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;households&lt;/td&gt;
&lt;td&gt;17000&lt;/td&gt;
&lt;td&gt;501.2219411764706&lt;/td&gt;
&lt;td&gt;384.5208408559016&lt;/td&gt;
&lt;td&gt;1.0&lt;/td&gt;
&lt;td&gt;6082.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;median_income&lt;/td&gt;
&lt;td&gt;17000&lt;/td&gt;
&lt;td&gt;3.883578100000021&lt;/td&gt;
&lt;td&gt;1.9081565183791036&lt;/td&gt;
&lt;td&gt;0.4999&lt;/td&gt;
&lt;td&gt;15.0001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;median_house_value&lt;/td&gt;
&lt;td&gt;17000&lt;/td&gt;
&lt;td&gt;207300.91235294117&lt;/td&gt;
&lt;td&gt;115983.76438720895&lt;/td&gt;
&lt;td&gt;14999.0&lt;/td&gt;
&lt;td&gt;500001.0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Descripcion estadistica de una sola columna (&amp;lsquo;median_house_value&amp;rsquo;)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df_spark.describe([&#39;median_house_value&#39;]).show()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;+-------+------------------+
|summary|median_house_value|
+-------+------------------+
|  count|             17000|
|   mean|207300.91235294117|
| stddev|115983.76438720895|
|    min|           14999.0|
|    max|          500001.0|
+-------+------------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;De esta forma se puede instalar automaticamente spark en google colab y hacer uno de el de forma gratis.&lt;/p&gt;
&lt;p&gt;En la version gratis solo se cuenta con una CPU si se quiere aumentar la capacidad de procesamiento es necesario pagar.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
