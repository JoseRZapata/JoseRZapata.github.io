<!DOCTYPE html><html lang="en-us" >

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.1.0 for Hugo" />
  

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Jose R. Zapata" />

  
  
  
    
  
  <meta name="description" content="Ejemplo Regresion con Python" />

  
  <link rel="alternate" hreflang="en-us" href="https://joserzapata.github.io/courses/python-ciencia-datos/clasificacion/" />

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    <meta name="theme-color" content="#328cc1" />
  

  
  

  
  
  
  
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">

    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css" integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.98dcc3bd98f20f708752b6d3d8cd160e.css" />

  




<script async src="https://www.googletagmanager.com/gtag/js?id=UA-112535090-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-112535090-1', {});
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  

  

  




  
  
  

  
    <link rel="alternate" href="/courses/python-ciencia-datos/clasificacion/index.xml" type="application/rss+xml" title="Jose Ricardo Zapata" />
  

  
    <link rel="manifest" href="/index.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_32x32_fill_lanczos_center_2.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_180x180_fill_lanczos_center_2.png" />

  <link rel="canonical" href="https://joserzapata.github.io/courses/python-ciencia-datos/clasificacion/" />

  
  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary" />
  
    <meta property="twitter:site" content="@joserzapata" />
    <meta property="twitter:creator" content="@joserzapata" />
  
  <meta property="og:site_name" content="Jose Ricardo Zapata" />
  <meta property="og:url" content="https://joserzapata.github.io/courses/python-ciencia-datos/clasificacion/" />
  <meta property="og:title" content="Clasificacion con Scikit Learn | Jose Ricardo Zapata" />
  <meta property="og:description" content="Ejemplo Regresion con Python" /><meta property="og:image" content="https://joserzapata.github.io/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_2.png" />
    <meta property="twitter:image" content="https://joserzapata.github.io/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_2.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta property="og:updated_time" content="2020-09-09T00:00:00&#43;00:00" />
    
  

  



  

  





  <title>Clasificacion con Scikit Learn | Jose Ricardo Zapata</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="b1978251a73229b908ac3c3369cce89b" >

  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.226a9011996d125bf3fe4a5f22353a49.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container-xl">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Jose Ricardo Zapata</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Jose Ricardo Zapata</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Blog</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#featured"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#teaching"><span>Teaching</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#talks"><span>Talks</span></a>
        </li>

        
        

        

        
        
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/phd"><span>Phd Thesis</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

      
      
        
          
          <li class="nav-item d-none d-lg-inline-flex">
            <a class="nav-link" href="https://twitter.com/joserzapata" target="_blank" rel="noopener" aria-label="twitter">
              <i class="fab fa-twitter" aria-hidden="true"></i>
            </a>
          </li>
        
          
          <li class="nav-item d-none d-lg-inline-flex">
            <a class="nav-link" href="https://www.linkedin.com/in/jose-ricardo-zapata-gonzalez/" target="_blank" rel="noopener" aria-label="linkedin">
              <i class="fab fa-linkedin" aria-hidden="true"></i>
            </a>
          </li>
        
      

      
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
          <i class="fas fa-moon" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      
      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    





<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      <form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-md-3 w-100" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <div class="d-flex">
      <span class="d-md-none pl-1 flex-grow-1 text-left overflow-hidden">
        
          Ciencia de Datos con Python
        
      </span>
      <span><i class="fas fa-chevron-down"></i></span>
    </div>
  </button>

  
  <button class="form-control sidebar-search js-search d-none d-md-flex">
    <i class="fas fa-search pr-2"></i>
    <span class="sidebar-search-text">Search...</span>
    <span class="sidebar-search-shortcut">/</span>
  </button>
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  
  
  
  
  
  

  
  
    

    
      

      <ul class="nav docs-sidenav">
        <li><a href="/courses/"><i class="fas fa-arrow-left pr-1"></i>Courses</a></li>
      </ul>

      
      
        
          
        
      


  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/courses/python-ciencia-datos/">Ciencia de Datos con Python</a>
    
      
        <ul class="nav docs-sidenav">
      


  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/courses/python-ciencia-datos/python/"><i class="fas fa-book pr-1"></i>1. Python</a>
    

    
      </div>
    



  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/courses/python-ciencia-datos/numpy/"><i class="fas fa-book pr-1"></i>2. Numpy</a>
    

    
      </div>
    



  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/courses/python-ciencia-datos/pandas/"><i class="fas fa-book pr-1"></i>3. Pandas</a>
    

    
      </div>
    



  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/courses/python-ciencia-datos/visualizacion/"><i class="fas fa-book pr-1"></i>4. Visualizacion</a>
    

    
      </div>
    



  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/courses/python-ciencia-datos/ml/"><i class="fas fa-book pr-1"></i>5. Machine Learning</a>
    

    
      </div>
    



  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/courses/python-ciencia-datos/regresion/"><i class="fas fa-book pr-1"></i>6. Regresion</a>
    

    
      </div>
    



  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link  active" href="/courses/python-ciencia-datos/clasificacion/"><i class="fas fa-book pr-1"></i>7. Clasificacion</a>
    

    
      </div>
    



  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/courses/python-ciencia-datos/clustering/"><i class="fas fa-book pr-1"></i>8. Clustering</a>
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    

    
  
</nav>

    </div>

    
    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      

      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>

      <nav id="TableOfContents">
  <ul>
    <li><a href="#eliminar-columnas-no-necesarias">Eliminar columnas no necesarias</a></li>
    <li><a href="#tratamiento-de-datos-nulos">Tratamiento de datos nulos</a></li>
    <li><a href="#descripcion-estadistica">Descripcion estadistica</a></li>
  </ul>

  <ul>
    <li><a href="#scatter-plots">Scatter Plots</a></li>
    <li><a href="#correlacion">Correlacion</a></li>
  </ul>

  <ul>
    <li><a href="#regresion-logistica-para-clasificacion">Regresion Logistica para Clasificacion</a>
      <ul>
        <li><a href="#matriz-de-confusion">Matriz de confusion</a></li>
        <li><a href="#precision---recall">Precision - recall</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#regresion-logistica">Regresion logistica</a></li>
    <li><a href="#lineal-discriminant-analysis">Lineal Discriminant Analysis</a></li>
    <li><a href="#quadratic-discriminant-analysis">Quadratic Discriminant Analysis</a></li>
    <li><a href="#sgd">SGD</a></li>
    <li><a href="#svc-lineal">SVC Lineal</a></li>
    <li><a href="#radius-neighbors-classifier">Radius Neighbors Classifier</a></li>
    <li><a href="#decision-tree-classifier">Decision Tree classifier</a></li>
    <li><a href="#naive-bayes">Naive Bayes</a></li>
  </ul>

  <ul>
    <li><a href="#decision-tree">Decision Tree</a></li>
    <li><a href="#regresion-logistica-1">Regresion logistica</a></li>
  </ul>
</nav>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article">

        <div class="docs-article-container">
          

          <h1>Clasificacion con Scikit Learn</h1>

          <div class="article-style">
            <p>Por <a href="https://joserzapata.github.io/" target="_blank" rel="noopener">Jose R. Zapata</a></p>
<script type="text/javascript" src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" data-name="bmc-button" data-slug="joserzapata" data-color="#328cc1" data-emoji="" data-font="Cookie" data-text="Invítame a un Café" data-outline-color="#000000" data-font-color="#ffffff" data-coffee-color="#FFDD00" ></script><br>
<p>Importar librerias</p>
<pre><code class="language-python">import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
</code></pre>
<h1 id="informacion-de-los-datos">Informacion de los Datos</h1>
<p>Titanic dataset</p>
<p>Fuente: <a href="https://www.kaggle.com/francksylla/titanic-machine-learning-from-disaster">https://www.kaggle.com/francksylla/titanic-machine-learning-from-disaster</a></p>
<pre><code class="language-python">titanic_df = pd.read_csv('datasets/titanic_train.csv')

titanic_df.head(10)
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>0</td>
      <td>3</td>
      <td>Moran, Mr. James</td>
      <td>male</td>
      <td>NaN</td>
      <td>0</td>
      <td>0</td>
      <td>330877</td>
      <td>8.4583</td>
      <td>NaN</td>
      <td>Q</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>0</td>
      <td>1</td>
      <td>McCarthy, Mr. Timothy J</td>
      <td>male</td>
      <td>54.0</td>
      <td>0</td>
      <td>0</td>
      <td>17463</td>
      <td>51.8625</td>
      <td>E46</td>
      <td>S</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8</td>
      <td>0</td>
      <td>3</td>
      <td>Palsson, Master. Gosta Leonard</td>
      <td>male</td>
      <td>2.0</td>
      <td>3</td>
      <td>1</td>
      <td>349909</td>
      <td>21.0750</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>8</th>
      <td>9</td>
      <td>1</td>
      <td>3</td>
      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>
      <td>female</td>
      <td>27.0</td>
      <td>0</td>
      <td>2</td>
      <td>347742</td>
      <td>11.1333</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10</td>
      <td>1</td>
      <td>2</td>
      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>
      <td>female</td>
      <td>14.0</td>
      <td>1</td>
      <td>0</td>
      <td>237736</td>
      <td>30.0708</td>
      <td>NaN</td>
      <td>C</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">titanic_df.shape
</code></pre>
<pre><code>(891, 12)
</code></pre>
<pre><code class="language-python">titanic_df.info()
</code></pre>
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   PassengerId  891 non-null    int64  
 1   Survived     891 non-null    int64  
 2   Pclass       891 non-null    int64  
 3   Name         891 non-null    object 
 4   Sex          891 non-null    object 
 5   Age          714 non-null    float64
 6   SibSp        891 non-null    int64  
 7   Parch        891 non-null    int64  
 8   Ticket       891 non-null    object 
 9   Fare         891 non-null    float64
 10  Cabin        204 non-null    object 
 11  Embarked     889 non-null    object 
dtypes: float64(2), int64(5), object(5)
memory usage: 83.7+ KB
</code></pre>
<h1 id="preparacion-de-datos">Preparacion de datos</h1>
<h2 id="eliminar-columnas-no-necesarias">Eliminar columnas no necesarias</h2>
<pre><code class="language-python">titanic_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], 'columns', inplace=True)

titanic_df.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.2500</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>71.2833</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.9250</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>53.1000</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>8.0500</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">titanic_df.info()
</code></pre>
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 891 entries, 0 to 890
Data columns (total 8 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   Survived  891 non-null    int64  
 1   Pclass    891 non-null    int64  
 2   Sex       891 non-null    object 
 3   Age       714 non-null    float64
 4   SibSp     891 non-null    int64  
 5   Parch     891 non-null    int64  
 6   Fare      891 non-null    float64
 7   Embarked  889 non-null    object 
dtypes: float64(2), int64(4), object(2)
memory usage: 55.8+ KB
</code></pre>
<h2 id="tratamiento-de-datos-nulos">Tratamiento de datos nulos</h2>
<pre><code class="language-python"># Contar el numero de datos nulos
titanic_df[titanic_df.isnull().any(axis=1)].count()
</code></pre>
<pre><code>Survived    179
Pclass      179
Sex         179
Age           2
SibSp       179
Parch       179
Fare        179
Embarked    177
dtype: int64
</code></pre>
<pre><code class="language-python"># eliminar las finlas con datos nulos
titanic_df = titanic_df.dropna()
</code></pre>
<pre><code class="language-python">titanic_df.shape
</code></pre>
<pre><code>(712, 8)
</code></pre>
<pre><code class="language-python">titanic_df[titanic_df.isnull().any(axis=1)].count()
</code></pre>
<pre><code>Survived    0
Pclass      0
Sex         0
Age         0
SibSp       0
Parch       0
Fare        0
Embarked    0
dtype: int64
</code></pre>
<h2 id="descripcion-estadistica">Descripcion estadistica</h2>
<pre><code class="language-python">titanic_df.describe()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>712.000000</td>
      <td>712.000000</td>
      <td>712.000000</td>
      <td>712.000000</td>
      <td>712.000000</td>
      <td>712.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.404494</td>
      <td>2.240169</td>
      <td>29.642093</td>
      <td>0.514045</td>
      <td>0.432584</td>
      <td>34.567251</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.491139</td>
      <td>0.836854</td>
      <td>14.492933</td>
      <td>0.930692</td>
      <td>0.854181</td>
      <td>52.938648</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.420000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>20.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>8.050000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>28.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>15.645850</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>38.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>33.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>80.000000</td>
      <td>5.000000</td>
      <td>6.000000</td>
      <td>512.329200</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">titanic_df.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.2500</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>71.2833</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.9250</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>53.1000</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>8.0500</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>
<h1 id="analisis-univariable">Analisis Univariable</h1>
<p>Se debe hacer un analisis de cada una de las variables y describir sus caracteristicas</p>
<h1 id="analisis-bivariable">Analisis Bivariable</h1>
<h2 id="scatter-plots">Scatter Plots</h2>
<pre><code class="language-python">fig, ax = plt.subplots(figsize=(12, 8))

plt.scatter(titanic_df['Age'], titanic_df['Survived'])

plt.xlabel('Age')
plt.ylabel('Survived');
</code></pre>
<p><img src="./8-Clasificacion-Python_21_0.png" alt="png"></p>
<pre><code class="language-python">fig, ax = plt.subplots(figsize=(12, 8))

plt.scatter(titanic_df['Fare'], titanic_df['Survived'])

plt.xlabel('Fare')
plt.ylabel('Survived');
</code></pre>
<p><img src="./8-Clasificacion-Python_22_0.png" alt="png"></p>
<h2 id="correlacion">Correlacion</h2>
<pre><code class="language-python">pd.crosstab(titanic_df['Sex'], titanic_df['Survived'])
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Survived</th>
      <th>0</th>
      <th>1</th>
    </tr>
    <tr>
      <th>Sex</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>female</th>
      <td>64</td>
      <td>195</td>
    </tr>
    <tr>
      <th>male</th>
      <td>360</td>
      <td>93</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">pd.crosstab(titanic_df['Pclass'], titanic_df['Survived'])
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Survived</th>
      <th>0</th>
      <th>1</th>
    </tr>
    <tr>
      <th>Pclass</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>64</td>
      <td>120</td>
    </tr>
    <tr>
      <th>2</th>
      <td>90</td>
      <td>83</td>
    </tr>
    <tr>
      <th>3</th>
      <td>270</td>
      <td>85</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">titanic_data_corr = titanic_df.corr()

titanic_data_corr
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Survived</th>
      <td>1.000000</td>
      <td>-0.356462</td>
      <td>-0.082446</td>
      <td>-0.015523</td>
      <td>0.095265</td>
      <td>0.266100</td>
    </tr>
    <tr>
      <th>Pclass</th>
      <td>-0.356462</td>
      <td>1.000000</td>
      <td>-0.365902</td>
      <td>0.065187</td>
      <td>0.023666</td>
      <td>-0.552893</td>
    </tr>
    <tr>
      <th>Age</th>
      <td>-0.082446</td>
      <td>-0.365902</td>
      <td>1.000000</td>
      <td>-0.307351</td>
      <td>-0.187896</td>
      <td>0.093143</td>
    </tr>
    <tr>
      <th>SibSp</th>
      <td>-0.015523</td>
      <td>0.065187</td>
      <td>-0.307351</td>
      <td>1.000000</td>
      <td>0.383338</td>
      <td>0.139860</td>
    </tr>
    <tr>
      <th>Parch</th>
      <td>0.095265</td>
      <td>0.023666</td>
      <td>-0.187896</td>
      <td>0.383338</td>
      <td>1.000000</td>
      <td>0.206624</td>
    </tr>
    <tr>
      <th>Fare</th>
      <td>0.266100</td>
      <td>-0.552893</td>
      <td>0.093143</td>
      <td>0.139860</td>
      <td>0.206624</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">fig, ax = plt.subplots(figsize=(12, 10))

sns.heatmap(titanic_data_corr, annot=True);
</code></pre>
<p><img src="./8-Clasificacion-Python_27_0.png" alt="png"></p>
<h1 id="transformacion-de-variables">Transformacion de Variables</h1>
<pre><code class="language-python">from sklearn import preprocessing

label_encoding = preprocessing.LabelEncoder()
titanic_df['Sex'] = label_encoding.fit_transform(titanic_df['Sex'].astype(str))

titanic_df.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.2500</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>71.2833</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>0</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.9250</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>53.1000</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>8.0500</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">label_encoding.classes_
</code></pre>
<pre><code>array(['female', 'male'], dtype=object)
</code></pre>
<p>C = Cherbourg,  Q = Queenstown,  S = Southampton</p>
<pre><code class="language-python">titanic_df = pd.get_dummies(titanic_df, columns=['Embarked'])

titanic_df.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Embarked_C</th>
      <th>Embarked_Q</th>
      <th>Embarked_S</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.2500</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>71.2833</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>0</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.9250</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>53.1000</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>8.0500</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">titanic_df = titanic_df.sample(frac=1).reset_index(drop=True)

titanic_df.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Embarked_C</th>
      <th>Embarked_Q</th>
      <th>Embarked_S</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>25.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.7750</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>27.0</td>
      <td>1</td>
      <td>0</td>
      <td>14.4542</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>51.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.0542</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>19.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.8958</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>34.0</td>
      <td>0</td>
      <td>0</td>
      <td>13.0000</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">titanic_df.to_csv('datasets/titanic_processed.csv', index=False)
</code></pre>
<h1 id="clasificacion-binaria">Clasificacion Binaria</h1>
<pre><code class="language-python">titanic_df = pd.read_csv('datasets/titanic_processed.csv')

titanic_df.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Embarked_C</th>
      <th>Embarked_Q</th>
      <th>Embarked_S</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>25.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.7750</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>27.0</td>
      <td>1</td>
      <td>0</td>
      <td>14.4542</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>51.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.0542</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>19.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.8958</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>34.0</td>
      <td>0</td>
      <td>0</td>
      <td>13.0000</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">titanic_df.shape
</code></pre>
<pre><code>(712, 10)
</code></pre>
<pre><code class="language-python">from sklearn.model_selection import train_test_split

X = titanic_df.drop('Survived', axis=1)
Y = titanic_df['Survived']

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)
</code></pre>
<pre><code class="language-python">x_train.shape, y_train.shape
</code></pre>
<pre><code>((569, 9), (569,))
</code></pre>
<pre><code class="language-python">x_test.shape, y_test.shape
</code></pre>
<pre><code>((143, 9), (143,))
</code></pre>
<h2 id="regresion-logistica-para-clasificacion">Regresion Logistica para Clasificacion</h2>
<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html</a></p>
<pre><code class="language-python">from sklearn.linear_model import LogisticRegression

logistic_model = LogisticRegression(penalty='l2', C=1.0, solver='liblinear').fit(x_train, y_train)
</code></pre>
<pre><code class="language-python">y_pred = logistic_model.predict(x_test)
</code></pre>
<h3 id="matriz-de-confusion">Matriz de confusion</h3>
<pre><code class="language-python">pred_results = pd.DataFrame({'y_test': y_test,
                             'y_pred': y_pred})
</code></pre>
<pre><code class="language-python">pred_results.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>y_test</th>
      <th>y_pred</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>484</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>102</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>65</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>30</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>38</th>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">titanic_crosstab = pd.crosstab(pred_results.y_pred, pred_results.y_test)

titanic_crosstab
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>y_test</th>
      <th>0</th>
      <th>1</th>
    </tr>
    <tr>
      <th>y_pred</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>75</td>
      <td>16</td>
    </tr>
    <tr>
      <th>1</th>
      <td>16</td>
      <td>36</td>
    </tr>
  </tbody>
</table>
</div>
<h3 id="precision---recall">Precision - recall</h3>
<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html</a>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html</a></p>
<pre><code class="language-python">from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
</code></pre>
<pre><code class="language-python">acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print(&quot;accuracy_score : &quot;, acc)
print(&quot;precision_score : &quot;, prec)
print(&quot;recall_score : &quot;, recall)
</code></pre>
<pre><code>accuracy_score :  0.7762237762237763
precision_score :  0.6923076923076923
recall_score :  0.6923076923076923
</code></pre>
<pre><code class="language-python">titanic_crosstab
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>y_test</th>
      <th>0</th>
      <th>1</th>
    </tr>
    <tr>
      <th>y_pred</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>75</td>
      <td>16</td>
    </tr>
    <tr>
      <th>1</th>
      <td>16</td>
      <td>36</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">TP = titanic_crosstab[1][1]
TN = titanic_crosstab[0][0]
FP = titanic_crosstab[0][1]
FN = titanic_crosstab[1][0]
</code></pre>
<pre><code class="language-python">accuracy_score_verified = (TP + TN) / (TP + FP + TN + FN)

accuracy_score_verified
</code></pre>
<pre><code>0.7762237762237763
</code></pre>
<pre><code class="language-python">precision_score_survived = TP / (TP + FP)

precision_score_survived
</code></pre>
<pre><code>0.6923076923076923
</code></pre>
<pre><code class="language-python">recall_score_survived = TP / (TP + FN)

recall_score_survived
</code></pre>
<pre><code>0.6923076923076923
</code></pre>
<h1 id="clasificacion-con-multiples-modelos">Clasificacion con Multiples Modelos</h1>
<pre><code class="language-python">from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

from sklearn.linear_model import LogisticRegression
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.linear_model import SGDClassifier
from sklearn.svm import LinearSVC
from sklearn.neighbors import RadiusNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
</code></pre>
<pre><code class="language-python">titanic_df = pd.read_csv('datasets/titanic_processed.csv')

titanic_df.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Embarked_C</th>
      <th>Embarked_Q</th>
      <th>Embarked_S</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>25.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.7750</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>27.0</td>
      <td>1</td>
      <td>0</td>
      <td>14.4542</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>51.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.0542</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>19.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.8958</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>34.0</td>
      <td>0</td>
      <td>0</td>
      <td>13.0000</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">FEATURES = list(titanic_df.columns[1:])

FEATURES
</code></pre>
<pre><code>['Pclass',
 'Sex',
 'Age',
 'SibSp',
 'Parch',
 'Fare',
 'Embarked_C',
 'Embarked_Q',
 'Embarked_S']
</code></pre>
<pre><code class="language-python">result_dict = {}
</code></pre>
<pre><code class="language-python">def summarize_classification(y_test, y_pred):
    
    acc = accuracy_score(y_test, y_pred, normalize=True)
    num_acc = accuracy_score(y_test, y_pred, normalize=False)

    prec = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    
    return {'accuracy': acc, 
            'precision': prec,
            'recall':recall, 
            'accuracy_count':num_acc}
</code></pre>
<pre><code class="language-python">def build_model(classifier_fn,                
                name_of_y_col, 
                names_of_x_cols, 
                dataset, 
                test_frac=0.2):
    
    X = dataset[names_of_x_cols]
    Y = dataset[name_of_y_col]

    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=test_frac)
       
    model = classifier_fn(x_train, y_train)
    
    y_pred = model.predict(x_test)

    y_pred_train = model.predict(x_train)
    
    train_summary = summarize_classification(y_train, y_pred_train)
    test_summary = summarize_classification(y_test, y_pred)
    
    pred_results = pd.DataFrame({'y_test': y_test,
                                 'y_pred': y_pred})
    
    model_crosstab = pd.crosstab(pred_results.y_pred, pred_results.y_test)
    
    return {'training': train_summary, 
            'test': test_summary,
            'confusion_matrix': model_crosstab}
</code></pre>
<pre><code class="language-python">def compare_results():
    for key in result_dict:
        print('Classification: ', key)

        print()
        print('Training data')
        for score in result_dict[key]['training']:
            print(score, result_dict[key]['training'][score])

        print()
        print('Test data')
        for score in result_dict[key]['test']:
            print(score, result_dict[key]['test'][score])
       
        print()
</code></pre>
<h2 id="regresion-logistica">Regresion logistica</h2>
<pre><code class="language-python">def logistic_fn(x_train, y_train):
    
    model = LogisticRegression(solver='liblinear')
    model.fit(x_train, y_train)
    
    return model
</code></pre>
<pre><code class="language-python">result_dict['survived ~ logistic'] = build_model(logistic_fn,
                                              'Survived',
                                               FEATURES,
                                               titanic_df)

compare_results()
</code></pre>
<pre><code>Classification:  survived ~ logistic

Training data
accuracy 0.8101933216168717
precision 0.8020304568527918
recall 0.6960352422907489
accuracy_count 461

Test data
accuracy 0.7692307692307693
precision 0.7692307692307693
recall 0.6557377049180327
accuracy_count 110
</code></pre>
<h2 id="lineal-discriminant-analysis">Lineal Discriminant Analysis</h2>
<pre><code class="language-python">def linear_discriminant_fn(x_train, y_train, solver='svd'):
    
    model = LinearDiscriminantAnalysis(solver=solver)
    model.fit(x_train, y_train)
    
    return model
</code></pre>
<pre><code class="language-python">result_dict['survived ~ linear_discriminant_analysis'] = build_model(linear_discriminant_fn,
                                                                 'Survived',
                                                                  FEATURES,
                                                                  titanic_df)
compare_results()
</code></pre>
<pre><code>Classification:  survived ~ logistic

Training data
accuracy 0.8101933216168717
precision 0.8020304568527918
recall 0.6960352422907489
accuracy_count 461

Test data
accuracy 0.7692307692307693
precision 0.7692307692307693
recall 0.6557377049180327
accuracy_count 110

Classification:  survived ~ linear_discriminant_analysis

Training data
accuracy 0.8014059753954306
precision 0.7782805429864253
recall 0.7288135593220338
accuracy_count 456

Test data
accuracy 0.7482517482517482
precision 0.6739130434782609
recall 0.5961538461538461
accuracy_count 107
</code></pre>
<pre><code class="language-python">result_dict['survived ~ linear_discriminant_analysis'] = build_model(linear_discriminant_fn,
                                                                     'Survived',
                                                                      FEATURES[0:-1],
                                                                      titanic_df)
compare_results()
</code></pre>
<pre><code>Classification:  survived ~ logistic

Training data
accuracy 0.8101933216168717
precision 0.8020304568527918
recall 0.6960352422907489
accuracy_count 461

Test data
accuracy 0.7692307692307693
precision 0.7692307692307693
recall 0.6557377049180327
accuracy_count 110

Classification:  survived ~ linear_discriminant_analysis

Training data
accuracy 0.8101933216168717
precision 0.7887323943661971
recall 0.7272727272727273
accuracy_count 461

Test data
accuracy 0.7622377622377622
precision 0.7555555555555555
recall 0.5964912280701754
accuracy_count 109
</code></pre>
<h2 id="quadratic-discriminant-analysis">Quadratic Discriminant Analysis</h2>
<pre><code class="language-python">def quadratic_discriminant_fn(x_train, y_train):
    
    model = QuadraticDiscriminantAnalysis()
    model.fit(x_train, y_train)
    
    return model
</code></pre>
<pre><code class="language-python">result_dict['survived ~ quadratic_discriminant_analysis'] = build_model(quadratic_discriminant_fn,
                                                                        'Survived',
                                                                        FEATURES[0:-1],
                                                                        titanic_df)

compare_results()
</code></pre>
<pre><code>Classification:  survived ~ logistic

Training data
accuracy 0.8101933216168717
precision 0.8020304568527918
recall 0.6960352422907489
accuracy_count 461

Test data
accuracy 0.7692307692307693
precision 0.7692307692307693
recall 0.6557377049180327
accuracy_count 110

Classification:  survived ~ linear_discriminant_analysis

Training data
accuracy 0.8101933216168717
precision 0.7887323943661971
recall 0.7272727272727273
accuracy_count 461

Test data
accuracy 0.7622377622377622
precision 0.7555555555555555
recall 0.5964912280701754
accuracy_count 109

Classification:  survived ~ quadratic_discriminant_analysis

Training data
accuracy 0.7943760984182777
precision 0.7594339622641509
recall 0.7092511013215859
accuracy_count 452

Test data
accuracy 0.8251748251748252
precision 0.8103448275862069
recall 0.7704918032786885
accuracy_count 118
</code></pre>
<h2 id="sgd">SGD</h2>
<pre><code class="language-python">def sgd_fn(x_train, y_train, max_iter=1000, tol=1e-3):
    
    model = SGDClassifier(max_iter=max_iter, tol=tol)
    model.fit(x_train, y_train)
     
    return model
</code></pre>
<pre><code class="language-python">result_dict['survived ~ sgd'] = build_model(sgd_fn,
                                           'Survived',
                                            FEATURES,
                                            titanic_df)

compare_results()
</code></pre>
<pre><code>Classification:  survived ~ logistic

Training data
accuracy 0.8101933216168717
precision 0.8020304568527918
recall 0.6960352422907489
accuracy_count 461

Test data
accuracy 0.7692307692307693
precision 0.7692307692307693
recall 0.6557377049180327
accuracy_count 110

Classification:  survived ~ linear_discriminant_analysis

Training data
accuracy 0.8101933216168717
precision 0.7887323943661971
recall 0.7272727272727273
accuracy_count 461

Test data
accuracy 0.7622377622377622
precision 0.7555555555555555
recall 0.5964912280701754
accuracy_count 109

Classification:  survived ~ quadratic_discriminant_analysis

Training data
accuracy 0.7943760984182777
precision 0.7594339622641509
recall 0.7092511013215859
accuracy_count 452

Test data
accuracy 0.8251748251748252
precision 0.8103448275862069
recall 0.7704918032786885
accuracy_count 118

Classification:  survived ~ sgd

Training data
accuracy 0.7504393673110721
precision 0.6554054054054054
recall 0.8290598290598291
accuracy_count 427

Test data
accuracy 0.7272727272727273
precision 0.6
recall 0.8333333333333334
accuracy_count 104
</code></pre>
<h2 id="svc-lineal">SVC Lineal</h2>
<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html">https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html</a></p>
<ul>
<li>SVC con kernel lineal</li>
<li>dual=False cuando el numero de muestras &gt; numero de caracteristicas</li>
</ul>
<pre><code class="language-python">def linear_svc_fn(x_train, y_train, C=1.0, max_iter=1000, tol=1e-3):
    
    model = LinearSVC(C=C, max_iter=max_iter, tol=tol, dual=False)
    model.fit(x_train, y_train) 
    
    return model
</code></pre>
<pre><code class="language-python">result_dict['survived ~ linear_svc'] = build_model(linear_svc_fn,
                                                  'Survived',
                                                   FEATURES,
                                                   titanic_df)

compare_results()
</code></pre>
<pre><code>Classification:  survived ~ logistic

Training data
accuracy 0.8101933216168717
precision 0.8020304568527918
recall 0.6960352422907489
accuracy_count 461

Test data
accuracy 0.7692307692307693
precision 0.7692307692307693
recall 0.6557377049180327
accuracy_count 110

Classification:  survived ~ linear_discriminant_analysis

Training data
accuracy 0.8101933216168717
precision 0.7887323943661971
recall 0.7272727272727273
accuracy_count 461

Test data
accuracy 0.7622377622377622
precision 0.7555555555555555
recall 0.5964912280701754
accuracy_count 109

Classification:  survived ~ quadratic_discriminant_analysis

Training data
accuracy 0.7943760984182777
precision 0.7594339622641509
recall 0.7092511013215859
accuracy_count 452

Test data
accuracy 0.8251748251748252
precision 0.8103448275862069
recall 0.7704918032786885
accuracy_count 118

Classification:  survived ~ sgd

Training data
accuracy 0.7504393673110721
precision 0.6554054054054054
recall 0.8290598290598291
accuracy_count 427

Test data
accuracy 0.7272727272727273
precision 0.6
recall 0.8333333333333334
accuracy_count 104

Classification:  survived ~ linear_svc

Training data
accuracy 0.7961335676625659
precision 0.7692307692307693
recall 0.7017543859649122
accuracy_count 453

Test data
accuracy 0.7762237762237763
precision 0.7333333333333333
recall 0.7333333333333333
accuracy_count 111
</code></pre>
<h2 id="radius-neighbors-classifier">Radius Neighbors Classifier</h2>
<pre><code class="language-python">def radius_neighbor_fn(x_train, y_train, radius=40.0):

    model = RadiusNeighborsClassifier(radius=radius)
    model.fit(x_train, y_train) 
    
    return model
</code></pre>
<pre><code class="language-python">result_dict['survived ~ radius_neighbors'] = build_model(radius_neighbor_fn,
                                                         'Survived',
                                                         FEATURES,
                                                         titanic_df)
compare_results()
</code></pre>
<pre><code>Classification:  survived ~ logistic

Training data
accuracy 0.8101933216168717
precision 0.8020304568527918
recall 0.6960352422907489
accuracy_count 461

Test data
accuracy 0.7692307692307693
precision 0.7692307692307693
recall 0.6557377049180327
accuracy_count 110

Classification:  survived ~ linear_discriminant_analysis

Training data
accuracy 0.8101933216168717
precision 0.7887323943661971
recall 0.7272727272727273
accuracy_count 461

Test data
accuracy 0.7622377622377622
precision 0.7555555555555555
recall 0.5964912280701754
accuracy_count 109

Classification:  survived ~ quadratic_discriminant_analysis

Training data
accuracy 0.7943760984182777
precision 0.7594339622641509
recall 0.7092511013215859
accuracy_count 452

Test data
accuracy 0.8251748251748252
precision 0.8103448275862069
recall 0.7704918032786885
accuracy_count 118

Classification:  survived ~ sgd

Training data
accuracy 0.7504393673110721
precision 0.6554054054054054
recall 0.8290598290598291
accuracy_count 427

Test data
accuracy 0.7272727272727273
precision 0.6
recall 0.8333333333333334
accuracy_count 104

Classification:  survived ~ linear_svc

Training data
accuracy 0.7961335676625659
precision 0.7692307692307693
recall 0.7017543859649122
accuracy_count 453

Test data
accuracy 0.7762237762237763
precision 0.7333333333333333
recall 0.7333333333333333
accuracy_count 111

Classification:  survived ~ radius_neighbors

Training data
accuracy 0.671353251318102
precision 0.7157894736842105
recall 0.2982456140350877
accuracy_count 382

Test data
accuracy 0.6433566433566433
precision 0.7142857142857143
recall 0.25
accuracy_count 92
</code></pre>
<h2 id="decision-tree-classifier">Decision Tree classifier</h2>
<p>max_depth = None [ If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples ]</p>
<p>max_features = None [None &ndash; max_features=n_features,
auto &ndash; then max_features=sqrt(n_features),
sqrt &ndash; then max_features=sqrt(n_features),
log2 &ndash; then max_features=log2(n_features)]</p>
<pre><code class="language-python">def decision_tree_fn(x_train, y_train, max_depth=None, max_features=None): 
    
    model = DecisionTreeClassifier(max_depth=max_depth, max_features=max_features)
    model.fit(x_train, y_train)
    
    return model
</code></pre>
<pre><code class="language-python">result_dict['survived ~ decision_tree'] = build_model(decision_tree_fn,
                                                 'Survived',
                                                  FEATURES,
                                                  titanic_df)

compare_results()
</code></pre>
<pre><code>Classification:  survived ~ logistic

Training data
accuracy 0.8101933216168717
precision 0.8020304568527918
recall 0.6960352422907489
accuracy_count 461

Test data
accuracy 0.7692307692307693
precision 0.7692307692307693
recall 0.6557377049180327
accuracy_count 110

Classification:  survived ~ linear_discriminant_analysis

Training data
accuracy 0.8101933216168717
precision 0.7887323943661971
recall 0.7272727272727273
accuracy_count 461

Test data
accuracy 0.7622377622377622
precision 0.7555555555555555
recall 0.5964912280701754
accuracy_count 109

Classification:  survived ~ quadratic_discriminant_analysis

Training data
accuracy 0.7943760984182777
precision 0.7594339622641509
recall 0.7092511013215859
accuracy_count 452

Test data
accuracy 0.8251748251748252
precision 0.8103448275862069
recall 0.7704918032786885
accuracy_count 118

Classification:  survived ~ sgd

Training data
accuracy 0.7504393673110721
precision 0.6554054054054054
recall 0.8290598290598291
accuracy_count 427

Test data
accuracy 0.7272727272727273
precision 0.6
recall 0.8333333333333334
accuracy_count 104

Classification:  survived ~ linear_svc

Training data
accuracy 0.7961335676625659
precision 0.7692307692307693
recall 0.7017543859649122
accuracy_count 453

Test data
accuracy 0.7762237762237763
precision 0.7333333333333333
recall 0.7333333333333333
accuracy_count 111

Classification:  survived ~ radius_neighbors

Training data
accuracy 0.671353251318102
precision 0.7157894736842105
recall 0.2982456140350877
accuracy_count 382

Test data
accuracy 0.6433566433566433
precision 0.7142857142857143
recall 0.25
accuracy_count 92

Classification:  survived ~ decision_tree

Training data
accuracy 0.9894551845342706
precision 1.0
recall 0.9737991266375546
accuracy_count 563

Test data
accuracy 0.6993006993006993
precision 0.6538461538461539
recall 0.576271186440678
accuracy_count 100
</code></pre>
<h2 id="naive-bayes">Naive Bayes</h2>
<pre><code class="language-python">def naive_bayes_fn(x_train,y_train, priors=None):
    
    model = GaussianNB(priors=priors)
    model.fit(x_train, y_train)
    
    return model
</code></pre>
<pre><code class="language-python">result_dict['survived ~ naive_bayes'] = build_model(naive_bayes_fn,
                                                    'Survived',
                                                    FEATURES,
                                                    titanic_df)

compare_results()
</code></pre>
<pre><code>Classification:  survived ~ logistic

Training data
accuracy 0.8101933216168717
precision 0.8020304568527918
recall 0.6960352422907489
accuracy_count 461

Test data
accuracy 0.7692307692307693
precision 0.7692307692307693
recall 0.6557377049180327
accuracy_count 110

Classification:  survived ~ linear_discriminant_analysis

Training data
accuracy 0.8101933216168717
precision 0.7887323943661971
recall 0.7272727272727273
accuracy_count 461

Test data
accuracy 0.7622377622377622
precision 0.7555555555555555
recall 0.5964912280701754
accuracy_count 109

Classification:  survived ~ quadratic_discriminant_analysis

Training data
accuracy 0.7943760984182777
precision 0.7594339622641509
recall 0.7092511013215859
accuracy_count 452

Test data
accuracy 0.8251748251748252
precision 0.8103448275862069
recall 0.7704918032786885
accuracy_count 118

Classification:  survived ~ sgd

Training data
accuracy 0.7504393673110721
precision 0.6554054054054054
recall 0.8290598290598291
accuracy_count 427

Test data
accuracy 0.7272727272727273
precision 0.6
recall 0.8333333333333334
accuracy_count 104

Classification:  survived ~ linear_svc

Training data
accuracy 0.7961335676625659
precision 0.7692307692307693
recall 0.7017543859649122
accuracy_count 453

Test data
accuracy 0.7762237762237763
precision 0.7333333333333333
recall 0.7333333333333333
accuracy_count 111

Classification:  survived ~ radius_neighbors

Training data
accuracy 0.671353251318102
precision 0.7157894736842105
recall 0.2982456140350877
accuracy_count 382

Test data
accuracy 0.6433566433566433
precision 0.7142857142857143
recall 0.25
accuracy_count 92

Classification:  survived ~ decision_tree

Training data
accuracy 0.9894551845342706
precision 1.0
recall 0.9737991266375546
accuracy_count 563

Test data
accuracy 0.6993006993006993
precision 0.6538461538461539
recall 0.576271186440678
accuracy_count 100

Classification:  survived ~ naive_bayes

Training data
accuracy 0.7644991212653779
precision 0.7032520325203252
recall 0.7393162393162394
accuracy_count 435

Test data
accuracy 0.7202797202797203
precision 0.6206896551724138
recall 0.6666666666666666
accuracy_count 103
</code></pre>
<h1 id="hyperparameter-tunning-optimizacion-de-hiperparametros">Hyperparameter tunning (Optimizacion de hiperparametros)</h1>
<pre><code class="language-python">titanic_df = pd.read_csv('datasets/titanic_processed.csv')

titanic_df.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Embarked_C</th>
      <th>Embarked_Q</th>
      <th>Embarked_S</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>25.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.7750</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>27.0</td>
      <td>1</td>
      <td>0</td>
      <td>14.4542</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>51.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.0542</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>19.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.8958</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>34.0</td>
      <td>0</td>
      <td>0</td>
      <td>13.0000</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">X = titanic_df.drop('Survived', axis=1)

Y = titanic_df['Survived']

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)
</code></pre>
<pre><code class="language-python">def summarize_classification(y_test, y_pred):
    
    acc = accuracy_score(y_test, y_pred, normalize=True)
    num_acc = accuracy_score(y_test, y_pred, normalize=False)

    prec = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    
    print(&quot;Test data count: &quot;,len(y_test))
    print(&quot;accuracy_count : &quot; , num_acc)
    print(&quot;accuracy_score : &quot; , acc)
    print(&quot;precision_score : &quot; , prec)
    print(&quot;recall_score : &quot;, recall)
    print()
</code></pre>
<h2 id="decision-tree">Decision Tree</h2>
<pre><code class="language-python">from sklearn.model_selection import GridSearchCV

parameters = {'max_depth': [2, 4, 5, 7, 9, 10]}

grid_search = GridSearchCV(DecisionTreeClassifier(), parameters, cv=3, return_train_score=True)
grid_search.fit(x_train, y_train)

grid_search.best_params_
</code></pre>
<pre><code>{'max_depth': 7}
</code></pre>
<pre><code class="language-python">for i in range(6):
    print('Parameters: ', grid_search.cv_results_['params'][i])

    print('Mean Test Score: ', grid_search.cv_results_['mean_test_score'][i])
    
    print('Rank: ', grid_search.cv_results_['rank_test_score'][i])
</code></pre>
<pre><code>Parameters:  {'max_depth': 2}
Mean Test Score:  0.797930010210712
Rank:  2
Parameters:  {'max_depth': 4}
Mean Test Score:  0.7978371855564838
Rank:  3
Parameters:  {'max_depth': 5}
Mean Test Score:  0.7855657662675206
Rank:  4
Parameters:  {'max_depth': 7}
Mean Test Score:  0.8102014294996751
Rank:  1
Parameters:  {'max_depth': 9}
Mean Test Score:  0.7768309663046504
Rank:  5
Parameters:  {'max_depth': 10}
Mean Test Score:  0.7733036294439802
Rank:  6
</code></pre>
<pre><code class="language-python">decision_tree_model = DecisionTreeClassifier( \
    max_depth = grid_search.best_params_['max_depth']).fit(x_train, y_train)
</code></pre>
<pre><code class="language-python">y_pred = decision_tree_model.predict(x_test)
</code></pre>
<pre><code class="language-python">summarize_classification(y_test, y_pred)
</code></pre>
<pre><code>Test data count:  143
accuracy_count :  112
accuracy_score :  0.7832167832167832
precision_score :  0.8604651162790697
recall_score :  0.5967741935483871
</code></pre>
<h2 id="regresion-logistica-1">Regresion logistica</h2>
<pre><code class="language-python">parameters = {'penalty': ['l1', 'l2'], 
              'C': [0.1, 0.4, 0.8, 1, 2, 5]}

grid_search = GridSearchCV(LogisticRegression(solver='liblinear'), parameters, cv=3, return_train_score=True)
grid_search.fit(x_train, y_train)

grid_search.best_params_
</code></pre>
<pre><code>{'C': 2, 'penalty': 'l1'}
</code></pre>
<pre><code class="language-python">for i in range(12):
    print('Parameters: ', grid_search.cv_results_['params'][i])
    print('Mean Test Score: ', grid_search.cv_results_['mean_test_score'][i])
    print('Rank: ', grid_search.cv_results_['rank_test_score'][i])
</code></pre>
<pre><code>Parameters:  {'C': 0.1, 'penalty': 'l1'}
Mean Test Score:  0.7803304557690524
Rank:  12
Parameters:  {'C': 0.1, 'penalty': 'l2'}
Mean Test Score:  0.780339738234475
Rank:  11
Parameters:  {'C': 0.4, 'penalty': 'l1'}
Mean Test Score:  0.7943562610229277
Rank:  7
Parameters:  {'C': 0.4, 'penalty': 'l2'}
Mean Test Score:  0.7855843311983662
Rank:  10
Parameters:  {'C': 0.8, 'penalty': 'l1'}
Mean Test Score:  0.7978557504873294
Rank:  4
Parameters:  {'C': 0.8, 'penalty': 'l2'}
Mean Test Score:  0.7961199294532628
Rank:  6
Parameters:  {'C': 1, 'penalty': 'l1'}
Mean Test Score:  0.7978557504873294
Rank:  4
Parameters:  {'C': 1, 'penalty': 'l2'}
Mean Test Score:  0.7996287013830874
Rank:  3
Parameters:  {'C': 2, 'penalty': 'l1'}
Mean Test Score:  0.8048825768124014
Rank:  1
Parameters:  {'C': 2, 'penalty': 'l2'}
Mean Test Score:  0.7943376960920822
Rank:  8
Parameters:  {'C': 5, 'penalty': 'l1'}
Mean Test Score:  0.8031096259166435
Rank:  2
Parameters:  {'C': 5, 'penalty': 'l2'}
Mean Test Score:  0.7943376960920822
Rank:  8
</code></pre>
<pre><code class="language-python">logistic_model = LogisticRegression(solver='liblinear', \
    penalty=grid_search.best_params_['penalty'], C=grid_search.best_params_['C']). \
    fit(x_train, y_train)
</code></pre>
<pre><code class="language-python">y_pred = logistic_model.predict(x_test)
</code></pre>
<pre><code class="language-python">summarize_classification(y_test, y_pred)
</code></pre>
<pre><code>Test data count:  143
accuracy_count :  110
accuracy_score :  0.7692307692307693
precision_score :  0.7543859649122807
recall_score :  0.6935483870967742
</code></pre>
<h1 id="grabar-el-modelo">Grabar el Modelo</h1>
<pre><code class="language-python">from joblib import dump, load # libreria de serializacion

# grabar el modelo en un archivo
dump(logistic_model, 'logistic_model-titanic.joblib')
</code></pre>
<pre><code>['logistic_model-titanic.joblib']
</code></pre>
<h1 id="referencias">Referencias</h1>
<p><a href="https://scikit-learn.org/stable/supervised_learning.html#supervised-learning">https://scikit-learn.org/stable/supervised_learning.html#supervised-learning</a></p>
<p>Cheatsheet scikitlearn
<a href="https://datacamp-community-prod.s3.amazonaws.com/5433fa18-9f43-44cc-b228-74672efcd116">https://datacamp-community-prod.s3.amazonaws.com/5433fa18-9f43-44cc-b228-74672efcd116</a></p>
<p><strong>Phd. Jose R. Zapata</strong></p>
<ul>
<li><a href="https://joserzapata.github.io/" target="_blank" rel="noopener">https://joserzapata.github.io/</a></li>
<li><a href="https://twitter.com/joserzapata">https://twitter.com/joserzapata</a></li>
</ul>

          </div>

          



          
          
          <div class="article-widget">
            
<div class="post-nav">
  
  
</div>

          </div>
          
        </div>

        <div class="body-footer">
          <p>Last updated on Sep 9, 2020</p>

          





          




          


  
  



        </div>

      </article>

      <footer class="site-footer">

  

  

  <p class="powered-by">
    © 2021
  </p>

  
  






  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-modules" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>


    </main>
  </div>
</div>

  </div>

  <div class="page-footer">
    
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      

      
      

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/shell.min.js"></script>
        
      

    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js" integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin="anonymous"></script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.2/anchor.min.js" integrity="sha512-I7w3ZdSFzw5j3jU3ZkNikBNeIrl3i+hEuEdwNmqUJvwNcaBUNcijnP2gd9DtGlgVYDplfjGoD8vTNsID+lCjqg==" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    <script src="/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js"></script>

    
    
      
      
      
      
      
      
      
    

    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.b61a8f62b6e5c0cd322c8158c5b5dfb6.js"></script>

    






</body>
</html>
