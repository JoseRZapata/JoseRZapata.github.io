<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jose R. Zapata | Jose Ricardo Zapata</title>
    <link>https://joserzapata.github.io/es/authors/jose-r.-zapata/</link>
      <atom:link href="https://joserzapata.github.io/es/authors/jose-r.-zapata/index.xml" rel="self" type="application/rss+xml" />
    <description>Jose R. Zapata</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>es</language><copyright>© 2020</copyright><lastBuildDate>Mon, 09 Mar 2020 23:00:43 -0500</lastBuildDate>
    <image>
      <url>https://joserzapata.github.io/img/JoseRZapata.jpg</url>
      <title>Jose R. Zapata</title>
      <link>https://joserzapata.github.io/es/authors/jose-r.-zapata/</link>
    </image>
    
    <item>
      <title>Pyspark con Google Colab</title>
      <link>https://joserzapata.github.io/es/post/pyspark-google-colab/</link>
      <pubDate>Mon, 09 Mar 2020 23:00:43 -0500</pubDate>
      <guid>https://joserzapata.github.io/es/post/pyspark-google-colab/</guid>
      <description>&lt;h1 id=&#34;pyspark-en-google-colab-automatico&#34;&gt;PySpark en Google Colab Automatico&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;Instalacion Marzo/2020&lt;/li&gt;
&lt;li&gt;Instalacion Java&lt;/li&gt;
&lt;li&gt;Instalacion de Spark&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;instalacion-marzo-2020&#34;&gt;Instalacion Marzo/ 2020&lt;/h2&gt;
&lt;p&gt;De forma General para usar pyspark en Colab Marzo/2020 seria con los siguientes comandos en una celda en Colab:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;apt&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;get install openjdk&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;jdk&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;headless &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;qq &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;dev&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;null

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os &lt;span style=&#34;color:#75715e&#34;&gt;# libreria de manejo del sistema operativo&lt;/span&gt;
os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;system(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;wget -q https://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz&amp;#34;&lt;/span&gt;)
os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;system(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;tar xf /spark-2.4.5-bin-hadoop2.7.tgz&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# instalar pyspark&lt;/span&gt;
&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;pip install &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;q pyspark
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Variables de Entorno&lt;/span&gt;
os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;environ[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;JAVA_HOME&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/usr/lib/jvm/java-8-openjdk-amd64&amp;#34;&lt;/span&gt;
os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;environ[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SPARK_HOME&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/content/{ver_spark}-bin-hadoop2.7&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Cargar Pyspark&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pyspark.sql &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; SparkSession
spark &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SparkSession&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;builder&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;appName(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Test_spark&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;master(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;local[*]&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;getOrCreate()
spark
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Pero cuadno salga una nueva version de spark sera necesario actualizar los
links de descarga, ya qeu siempre borran las versiones 2.x.x cuando sale una nueva.&lt;/p&gt;
&lt;p&gt;Lo mejor es configurar automaticamente para que descargue la version que sea
mayor que 2.3.4 que es la anterior y menor que spark 3.0.0 que aun se encuentra en desarrollo&lt;/p&gt;
&lt;p&gt;Para esto el siguiente codigo detecta la version actual de spark, la descarga, la descomprime y luego realiza la instalacion de spark en google colab.&lt;/p&gt;
&lt;h2 id=&#34;instalacion-de-java&#34;&gt;Instalacion de Java&lt;/h2&gt;
&lt;p&gt;Google Colaboratory funciona en un ambiente linux, por lo tanto se pueden usar comandos shell de linux antecedidos del caracter &amp;lsquo;!&amp;rsquo;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;!apt-get install openjdk-8-jdk-headless -qq &amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;instalacion-de-spark&#34;&gt;Instalacion de Spark&lt;/h2&gt;
&lt;p&gt;Obtener automaticamente la ultima version de spark de&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from bs4 import BeautifulSoup
import requests
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;#Obtener las versiones de spark la pagina web
url = &#39;https://downloads.apache.org/spark/&#39; 
r = requests.get(url)
html_doc = r.text
soup = BeautifulSoup(html_doc)
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;# leer la pagina web y obtener las versiones de spark disponibles
link_files = []
for link in soup.find_all(&#39;a&#39;):
  link_files.append(link.get(&#39;href&#39;))
spark_link = [x for x in link_files if &#39;spark&#39; in x]  
print(spark_link)
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;[&#39;spark-2.3.4/&#39;, &#39;spark-2.4.5/&#39;, &#39;spark-3.0.0-preview2/&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;La version a usar seran las superiores a spark-2.3.4  y menores a spark-3.0.0&lt;/p&gt;
&lt;p&gt;obtener la version y eliminar el caracter &amp;lsquo;/&amp;rsquo; del final&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ver_spark = spark_link[1][:-1] # obtener la version y eliminar el caracter &#39;/&#39; del final
print(ver_spark)
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;spark-2.4.5
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;import os # libreria de manejo del sistema operativo
#instalar automaticamente la version deseadda de spark
os.system(f&amp;quot;wget -q https://www-us.apache.org/dist/spark/{ver_spark}/{ver_spark}-bin-hadoop2.7.tgz&amp;quot;)
os.system(f&amp;quot;tar xf {ver_spark}-bin-hadoop2.7.tgz&amp;quot;)
# instalar pyspark
!pip install -q pyspark
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;|████████████████████████████████| 217.8MB 63kB/s 
|████████████████████████████████| 204kB 53.8MB/s 
Building wheel for pyspark (setup.py) ... done
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;definir-variables-de-entorno&#34;&gt;Definir variables de entorno&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;os.environ[&amp;quot;JAVA_HOME&amp;quot;] = &amp;quot;/usr/lib/jvm/java-8-openjdk-amd64&amp;quot;
os.environ[&amp;quot;SPARK_HOME&amp;quot;] = f&amp;quot;/content/{ver_spark}-bin-hadoop2.7&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;cargar-pyspark-en-el-sistema&#34;&gt;Cargar pyspark en el sistema&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;from pyspark.sql import SparkSession
spark = SparkSession.builder.appName(&amp;quot;Test_spark&amp;quot;).master(&amp;quot;local[*]&amp;quot;).getOrCreate()
spark
&lt;/code&gt;&lt;/pre&gt;&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h1 id=&#34;ejemplo-de-uso-de-pyspark&#34;&gt;Ejemplo de Uso de pyspark&lt;/h1&gt;
&lt;p&gt;Leer archivo de prueba&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;archivo = &#39;./sample_data/california_housing_train.csv&#39;
df_spark = spark.read.csv(archivo, inferSchema=True, header=True)

# imprimir tipo de archivo
print(type(df_spark))
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;class &#39;pyspark.sql.dataframe.DataFrame&#39;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;¿Numero de registros en el dataframe?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;df_spark.count()
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;17000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Estructura del dataframe&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;df_spark.printSchema()
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;root
 |-- longitude: double (nullable = true)
 |-- latitude: double (nullable = true)
 |-- housing_median_age: double (nullable = true)
 |-- total_rooms: double (nullable = true)
 |-- total_bedrooms: double (nullable = true)
 |-- population: double (nullable = true)
 |-- households: double (nullable = true)
 |-- median_income: double (nullable = true)
 |-- median_house_value: double (nullable = true)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;¿Nombre de las Columnas de dataframe?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;df_spark.columns
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;[&#39;longitude&#39;,
 &#39;latitude&#39;,
 &#39;housing_median_age&#39;,
 &#39;total_rooms&#39;,
 &#39;total_bedrooms&#39;,
 &#39;population&#39;,
 &#39;households&#39;,
 &#39;median_income&#39;,
 &#39;median_house_value&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ver los primeros 20 registros del dataframe&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;df_spark.show()
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+
|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|
+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+
|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|
|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|
|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|
|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|
|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|
|  -114.58|   33.63|              29.0|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|
|  -114.58|   33.61|              25.0|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|
|  -114.59|   34.83|              41.0|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|
|  -114.59|   33.61|              34.0|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|
|   -114.6|   34.83|              46.0|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|
|   -114.6|   33.62|              16.0|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|
|   -114.6|    33.6|              21.0|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|
|  -114.61|   34.84|              48.0|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|
|  -114.61|   34.83|              31.0|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0|
|  -114.63|   32.76|              15.0|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|
|  -114.65|   34.89|              17.0|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0|
|  -114.65|    33.6|              28.0|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|
|  -114.65|   32.79|              21.0|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0|
|  -114.66|   32.74|              17.0|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|
|  -114.67|   33.92|              17.0|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|
+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+
only showing top 20 rows
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;descricipcion-estadistica-del-dataframe&#34;&gt;Descricipcion Estadistica del dataframe&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;df_spark.describe().toPandas().transpose()
&lt;/code&gt;&lt;/pre&gt;&lt;!-- raw HTML omitted --&gt;
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Descripcion estadistica de una sola columna (&amp;lsquo;median_house_value&amp;rsquo;)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;df_spark.describe([&#39;median_house_value&#39;]).show()
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;+-------+------------------+
|summary|median_house_value|
+-------+------------------+
|  count|             17000|
|   mean|207300.91235294117|
| stddev|115983.76438720895|
|    min|           14999.0|
|    max|          500001.0|
+-------+------------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;De esta forma se puede instalar automaticamente spark en google colab y hacer uno de el de forma gratis.&lt;/p&gt;
&lt;p&gt;En la version gratis solo se cuenta con una CPU si se quiere aumentar la capacidad de procesamiento es necesario pagar.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Comprensión de la música con Python, una mirada desde la Física y la Matemática</title>
      <link>https://joserzapata.github.io/es/talk/pycon2020/</link>
      <pubDate>Fri, 07 Feb 2020 12:35:00 -0500</pubDate>
      <guid>https://joserzapata.github.io/es/talk/pycon2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Aplicaciones de Audio con Machine Learning</title>
      <link>https://joserzapata.github.io/es/talk/meetup_2018/</link>
      <pubDate>Tue, 02 Oct 2018 18:00:00 -0500</pubDate>
      <guid>https://joserzapata.github.io/es/talk/meetup_2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Analisis de Señales de Audio con Python</title>
      <link>https://joserzapata.github.io/es/talk/pycon2018/</link>
      <pubDate>Fri, 09 Feb 2018 11:40:35 -0500</pubDate>
      <guid>https://joserzapata.github.io/es/talk/pycon2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Tempo Estimation</title>
      <link>https://joserzapata.github.io/es/publication/tempo-estimation/</link>
      <pubDate>Thu, 17 Nov 2016 18:14:05 -0500</pubDate>
      <guid>https://joserzapata.github.io/es/publication/tempo-estimation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sistemas Automaticos para Extraccion de Información Musical (Generalidades y Aplicaciones)</title>
      <link>https://joserzapata.github.io/es/talk/aes2016/</link>
      <pubDate>Fri, 22 Jul 2016 14:00:00 -0500</pubDate>
      <guid>https://joserzapata.github.io/es/talk/aes2016/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multi-Feature Beat Tracking</title>
      <link>https://joserzapata.github.io/es/publication/multifeature-beattracker/</link>
      <pubDate>Thu, 03 Apr 2014 11:52:17 -0500</pubDate>
      <guid>https://joserzapata.github.io/es/publication/multifeature-beattracker/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Essentia: An Audio Analysis Library for Music Information Retrieval</title>
      <link>https://joserzapata.github.io/es/publication/essentia-ismir/</link>
      <pubDate>Sun, 03 Nov 2013 23:32:53 -0500</pubDate>
      <guid>https://joserzapata.github.io/es/publication/essentia-ismir/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Essentia: an open-source library for sound and music analysis</title>
      <link>https://joserzapata.github.io/es/publication/essentia-acm/</link>
      <pubDate>Mon, 21 Oct 2013 00:11:35 -0500</pubDate>
      <guid>https://joserzapata.github.io/es/publication/essentia-acm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Comparative evaluation and combination of automatic rhythm description systems</title>
      <link>https://joserzapata.github.io/es/publication/phd-thesis/</link>
      <pubDate>Fri, 13 Sep 2013 14:49:50 +0100</pubDate>
      <guid>https://joserzapata.github.io/es/publication/phd-thesis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Using voice suppression algorithms to improve beat tracking in the presence of highly predominant vocals</title>
      <link>https://joserzapata.github.io/es/publication/voice-suppression-improve-beat-tracking/</link>
      <pubDate>Sun, 26 May 2013 12:42:45 -0500</pubDate>
      <guid>https://joserzapata.github.io/es/publication/voice-suppression-improve-beat-tracking/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Selective Sampling for Beat Tracking Evaluation</title>
      <link>https://joserzapata.github.io/es/publication/selective-sampling-beat-tracking/</link>
      <pubDate>Sat, 03 Nov 2012 12:16:05 -0500</pubDate>
      <guid>https://joserzapata.github.io/es/publication/selective-sampling-beat-tracking/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Assigning a confidence threshold on automatic beat annotation in large datasets</title>
      <link>https://joserzapata.github.io/es/publication/assigning-confidence/</link>
      <pubDate>Mon, 08 Oct 2012 19:38:56 -0500</pubDate>
      <guid>https://joserzapata.github.io/es/publication/assigning-confidence/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Improving Beat Tracking in the presence of highly predominant vocals using source separation techniques: Preliminary study</title>
      <link>https://joserzapata.github.io/es/publication/improving-beat-tracking/</link>
      <pubDate>Thu, 28 Jun 2012 22:17:42 -0500</pubDate>
      <guid>https://joserzapata.github.io/es/publication/improving-beat-tracking/</guid>
      <description></description>
    </item>
    
    <item>
      <title>On the automatic identification of difficult examples for beat tracking: towards building new evaluation datasets</title>
      <link>https://joserzapata.github.io/es/publication/automatic-identification/</link>
      <pubDate>Sun, 25 Mar 2012 19:44:33 -0500</pubDate>
      <guid>https://joserzapata.github.io/es/publication/automatic-identification/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Comparative Evaluation and Combination of Audio Tempo Estimation Approaches</title>
      <link>https://joserzapata.github.io/es/publication/comparative-tempo/</link>
      <pubDate>Fri, 22 Jul 2011 12:33:35 -0500</pubDate>
      <guid>https://joserzapata.github.io/es/publication/comparative-tempo/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Efficient Detection of Exact Redundancies in Audio Signals</title>
      <link>https://joserzapata.github.io/es/publication/efficient-detection/</link>
      <pubDate>Wed, 01 Oct 2008 22:34:53 -0500</pubDate>
      <guid>https://joserzapata.github.io/es/publication/efficient-detection/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Control de Rango Dinamico en Audio con Logica Difusa</title>
      <link>https://joserzapata.github.io/es/publication/control-rango-dinamico/</link>
      <pubDate>Sun, 25 Jul 2004 13:40:24 -0500</pubDate>
      <guid>https://joserzapata.github.io/es/publication/control-rango-dinamico/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
